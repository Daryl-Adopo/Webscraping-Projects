{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Coding Sample\n",
    "#### By Daryl Adopo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any web scraping require a basic knowlege of HTML.\n",
    "The basic HTML Styntax of any webpage looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>   \n",
       "    <head>\n",
       "    <meta charset=\"utf-8\">\n",
       "    </head>\n",
       "    <body>\n",
       "        <h1 class = \"heading\"> My Website </h1>\n",
       "        <p>Hello World! </p>\n",
       "    <body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<!DOCTYPE html>   \n",
    "    <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1 class = \"heading\"> My Website </h1>\n",
    "        <p>Hello World! </p>\n",
    "    <body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every tag in HTML can have attribute information such as **class**, **id**, **href**, and other useful information that helps to uniquely identify the element.\n",
    "\n",
    "For more information about basic HTML tags, check out [w3schools](https://www.w3schools.com/html/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this sample, I used:\n",
    "- **requests** to get the raw HTML\n",
    "- **BeautifulSoup** to parse HTML in python\n",
    "- **csv** to export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "try:\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    import csv\n",
    "except ImportError:\n",
    "    %%capture\n",
    "    !pip install bs4\n",
    "    !pip install requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import requests\n",
    "    import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the Major League Baseball Salaries Data publicly available on [spotrac.com](https://www.spotrac.com/mlb/rankings/2021/salary/). \\\n",
    "I am not really a Baseball fan, but I am currently working on a project requiring this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.spotrac.com/mlb/rankings/2021/salary/\" width=\"800\" height=\"500\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.spotrac.com/mlb/rankings/2021/salary/\" width=\"800\" height=\"500\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.spotrac.com/mlb/rankings/2021/salary/\"\n",
    "\n",
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse the html content\n",
    "soup = BeautifulSoup(html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take a look at the source code of the page to know where I can find the data that I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify()) # print the parsed data of html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the source code, I notice the table with the player salaries is embeded in the **table** tag with the attribute **class = \"datatable noborder\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Table of interest on the webpage\n",
    "mlb_table = soup.find(\"table\", attrs={\"class\": \"datatable noborder\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since my goal is to extract (scrape) the data from this table,\n",
    "\\\n",
    "I will need to store each row of the table as dictionary with the headings as keys to conform to the format of the **CSV** package.\n",
    "\n",
    "After a process long process of trial and error, I am able to store the information as I need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_table_header = mlb_table.thead.find_all(\"tr\") # Headers\n",
    "mlb_table_data = mlb_table.tbody.find_all(\"tr\")  # Rows\n",
    "\n",
    "# Extract Information from the Table\n",
    "# Get all the headings\n",
    "headings = []\n",
    "for th in mlb_table_header[0].find_all(\"th\"):\n",
    "    # remove any newlines and extra spaces from left and right\n",
    "    headings.append(th.text.replace('\\n', ' ').strip())\n",
    "    \n",
    "data = []\n",
    "for tr in mlb_table_data: # find all tr's from table's tbody\n",
    "\n",
    "    row = {}\n",
    "    # Each row is stored in the form of\n",
    "    # row = {'Rank': '', 'Player': '',etc...}\n",
    "\n",
    "    # find all td's in tr and zip it with headings\n",
    "    for td, th in zip(tr.find_all(\"td\"), headings):\n",
    "        if td.attrs:\n",
    "            # Getting the player name only\n",
    "            if td.attrs['class'][0] == \"rank-name\":\n",
    "                row[th] = td.find('h3').text.replace('\\n', '').strip()\n",
    "                # Creating custom column for the team code\n",
    "                row['code'] = td.find('div', \"rank-position\").text.replace('\\n', '').strip()\n",
    "                continue\n",
    "        row[th] = td.text.replace('\\n', '').strip()\n",
    "    data.append(row)\n",
    "\n",
    "# Adding custom column to headings\n",
    "headings.insert(3, 'code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am ready to export the data as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Table as a CSV File\n",
    "with open(f\"mlb_player_salary.csv\", 'w', newline = '') as out_file:\n",
    "    writer = csv.DictWriter(out_file, headings)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I know what I am doing, I can automate the process to get the player salaries for each teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Teams Url\n",
    "\n",
    "First I need a list of all the teams on the website\n",
    "\n",
    "After inspection of the source code, I notice that the team urls are embeded in the **select** tag with attribute **name=\"teamUrl\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'arizona-diamondbacks', 'atlanta-braves', 'baltimore-orioles', 'boston-red-sox', 'chicago-cubs', 'chicago-white-sox', 'cincinnati-reds', 'cleveland-indians', 'colorado-rockies', 'detroit-tigers', 'houston-astros', 'kansas-city-royals', 'los-angeles-angels', 'los-angeles-dodgers', 'miami-marlins', 'milwaukee-brewers', 'minnesota-twins', 'new-york-mets', 'new-york-yankees', 'oakland-athletics', 'philadelphia-phillies', 'pittsburgh-pirates', 'san-diego-padres', 'san-francisco-giants', 'seattle-mariners', 'st-louis-cardinals', 'tampa-bay-rays', 'texas-rangers', 'toronto-blue-jays', 'washington-nationals']\n"
     ]
    }
   ],
   "source": [
    "mlb_teams = soup.find(\"select\", attrs={\"name\": \"teamUrl1\"})\n",
    "mlb_teams_data = mlb_teams.find_all('option')\n",
    "\n",
    "# Storing team url\n",
    "teams = []\n",
    "for option in mlb_teams_data:\n",
    "    teams.append(option.attrs['value'])\n",
    "    \n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I dynamically request the pages for each team, and extract the data using the code from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for team in teams:\n",
    "    url=f\"https://www.spotrac.com/mlb/rankings/2021/salary/{team}\"\n",
    "\n",
    "    # Make a GET request to fetch the raw HTML content\n",
    "    html_content = requests.get(url).text\n",
    "\n",
    "    # Parse the html content\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    \n",
    "    # Find Table of interest on the webpage\n",
    "    mlb_table = soup.find(\"table\", attrs={\"class\": \"datatable noborder\"})\n",
    "\n",
    "    mlb_table_header = mlb_table.thead.find_all(\"tr\") # Headers\n",
    "    mlb_table_data = mlb_table.tbody.find_all(\"tr\")  # Rows\n",
    "    \n",
    "    # Extract Information from the Table\n",
    "    # Get all the headings\n",
    "    headings = []\n",
    "    for th in mlb_table_header[0].find_all(\"th\"):\n",
    "        # remove any newlines and extra spaces from left and right\n",
    "        headings.append(th.text.replace('\\n', ' ').strip())\n",
    "    \n",
    "    data = []\n",
    "    for tr in mlb_table_data: # find all tr's from table's tbody\n",
    "\n",
    "        row = {}\n",
    "        # Each row is stored in the form of\n",
    "        # row = {'Rank': '', 'Player': '',etc...}\n",
    "\n",
    "        # find all td's in tr and zip it with headings\n",
    "        for td, th in zip(tr.find_all(\"td\"), headings):\n",
    "            if td.attrs:\n",
    "                # Getting the player name only\n",
    "                if td.attrs['class'][0] == \"rank-name\":\n",
    "                    row[th] = td.find('h3').text.replace('\\n', '').strip()\n",
    "                    # Creating custom column for team code\n",
    "                    row['code'] = td.find('div', \"rank-position\").text.replace('\\n', '').strip()\n",
    "                    continue\n",
    "            row[th] = td.text.replace('\\n', '').strip()\n",
    "        data.append(row)\n",
    "\n",
    "    # Adding custom column to headings\n",
    "    headings.insert(3, 'code')\n",
    "    \n",
    "    # Exporting Table to Excel\n",
    "    with open(f\"mlb_player_salary_{team}.csv\", 'w', newline = '') as out_file:\n",
    "        writer = csv.DictWriter(out_file, headings)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
